To solve this task, I will iterate over the given binary matrix `grid` and calculate the number of ones and zeros in each row and each column. Then, I will populate the `diff` matrix accordingly.

Here's the implementation in Go:

```go
func onesMinusZeros(grid [][]int) [][]int {
    m := len(grid)
    n := len(grid[0])
    
    onesRow := make([]int, m) // number of ones in each row
    onesCol := make([]int, n) // number of ones in each column
    zerosRow := make([]int, m) // number of zeros in each row
    zerosCol := make([]int, n) // number of zeros in each column
    
    // calculate the number of ones and zeros in each row and each column
    for i := 0; i < m; i++ {
        for j := 0; j < n; j++ {
            if grid[i][j] == 1 {
                onesRow[i]++
                onesCol[j]++
            } else {
                zerosRow[i]++
                zerosCol[j]++
            }
        }
    }
    
    // calculate the difference matrix diff
    diff := make([][]int, m)
    for i := 0; i < m; i++ {
        diff[i] = make([]int, n)
        for j := 0; j < n; j++ {
            diff[i][j] = onesRow[i] + onesCol[j] - zerosRow[i] - zerosCol[j]
        }
    }
    
    return diff
}
```

The function `onesMinusZeros` takes the binary matrix `grid` as input and returns the difference matrix `diff`.

The main idea is to iterate over the grid and calculate the number of ones and zeros in each row and each column. This is done by using two separate arrays `onesRow` and `onesCol` to keep track of the count of ones, and two separate arrays `zerosRow` and `zerosCol` to keep track of the count of zeros.

Then, we iterate over the grid again and calculate the difference matrix `diff` by subtracting the count of zeros in the row and column from the count of ones in the row and column.

Finally, we return the `diff` matrix.

Note: The given binary matrix `grid` is guaranteed to be a valid input, so no need to check for input validity.