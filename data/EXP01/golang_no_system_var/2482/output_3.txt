Here is one possible implementation of the solution in Go:

```go
func onesMinusZeros(grid [][]int) [][]int {
    m := len(grid)
    n := len(grid[0])
    
    // Calculate the count of ones and zeros in each row and column
    onesRow := make([]int, m)
    onesCol := make([]int, n)
    zerosRow := make([]int, m)
    zerosCol := make([]int, n)
    
    for i := 0; i < m; i++ {
        for j := 0; j < n; j++ {
            if grid[i][j] == 1 {
                onesRow[i]++
                onesCol[j]++
            } else {
                zerosRow[i]++
                zerosCol[j]++
            }
        }
    }
    
    // Calculate the difference matrix
    diff := make([][]int, m)
    for i := 0; i < m; i++ {
        diff[i] = make([]int, n)
        for j := 0; j < n; j++ {
            diff[i][j] = onesRow[i] + onesCol[j] - zerosRow[i] - zerosCol[j]
        }
    }
    
    return diff
}
```

This solution first calculates the count of ones and zeros in each row and column of the input grid using nested loops. Then, it creates a new matrix `diff` with the same dimensions as the input grid and calculates the difference between ones and zeros for each element of `diff` using another set of nested loops. Finally, it returns the `diff` matrix.

Note that this implementation assumes that the input grid is a valid binary matrix with equal lengths for each row and column. If this assumption is not guaranteed, additional checks and error handling should be added.