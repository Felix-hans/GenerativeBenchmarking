The main idea to solve this problem is to iterate through each node in the graph and calculate the maximum star sum centered at that node. To do this, we can use a depth-first search (DFS) algorithm.

We will define a helper function called dfs that takes the current node, its parent node, and the number of edges used so far as parameters. In the dfs function, we will iterate through each neighbor of the current node and recursively call the dfs function on each neighbor, updating the number of edges used and the maximum star sum accordingly.

Here is the implementation of the solution in Go:

```go
func maxStarSum(vals []int, edges [][]int, k int) int {
    n := len(vals)
    graph := make(map[int][]int)
    for _, edge := range edges {
        a, b := edge[0], edge[1]
        graph[a] = append(graph[a], b)
        graph[b] = append(graph[b], a)
    }
    
    maxSum := vals[0] // initialize maxSum with the value of the first node
    
    var dfs func(int, int, int) int
    dfs = func(node, parent, edgesUsed int) int {
        sum := vals[node]
        children := 0
        
        for _, neighbor := range graph[node] {
            if neighbor != parent {
                childSum := dfs(neighbor, node, edgesUsed+1)
                if childSum > 0 {
                    sum += childSum
                    children++
                }
            }
        }
        
        if children == 0 && edgesUsed <= k {
            return sum
        }
        
        if edgesUsed < k && sum > maxSum {
            maxSum = sum
        }
        
        return sum
    }
    
    dfs(0, -1, 0) // start DFS from the first node
    
    return maxSum
}
```

The time complexity of this solution is O(n + m), where n is the number of nodes and m is the number of edges in the graph. The space complexity is O(n) to store the graph adjacency list.