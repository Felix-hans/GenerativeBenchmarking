To implement the LRU cache in Python, we can use a combination of a dictionary (hash map) and a doubly linked list. The dictionary will provide fast access to the cache values using keys, while the doubly linked list will keep track of the most recently used items and their order.

Here's the implementation:

```python
class ListNode:
    def __init__(self, key=None, value=None):
        self.key = key
        self.value = value
        self.prev = None
        self.next = None


class LRUCache:
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.cache = {}
        self.head = ListNode()
        self.tail = ListNode()
        self.head.next = self.tail
        self.tail.prev = self.head

    def get(self, key: int) -> int:
        if key in self.cache:
            node = self.cache[key]
            self._remove_node(node)
            self._add_to_head(node)
            return node.value
        return -1

    def put(self, key: int, value: int) -> None:
        if key in self.cache:
            node = self.cache[key]
            node.value = value
            self._remove_node(node)
        else:
            node = ListNode(key, value)
            self.cache[key] = node
            if len(self.cache) > self.capacity:
                del_node = self.tail.prev
                self._remove_node(del_node)
                del self.cache[del_node.key]
        self._add_to_head(node)

    def _remove_node(self, node: ListNode) -> None:
        node.prev.next = node.next
        node.next.prev = node.prev

    def _add_to_head(self, node: ListNode) -> None:
        node.prev = self.head
        node.next = self.head.next
        self.head.next.prev = node
        self.head.next = node
```

In this implementation, we define a `ListNode` class to represent each node in the doubly linked list. Each node contains a key, value, a reference to the previous node (`prev`), and a reference to the next node (`next`).

The `LRUCache` class has an `__init__` method that initializes the cache with the given capacity. It also initializes the `cache` dictionary to store the key-node mappings and creates the dummy head and tail nodes for the doubly linked list.

The `get` method retrieves the value associated with the given key from the cache. If the key exists, it moves the corresponding node to the front of the list (to indicate it was recently used) and returns the value. If the key doesn't exist, it returns -1.

The `put` method updates the value associated with the given key in the cache. If the key exists, it updates the value and moves the corresponding node to the front of the list. If the key doesn't exist, it creates a new node and adds it to the front of the list. If the cache exceeds its capacity, it removes the least recently used node (which is the one before the tail) from both the list and the cache.

The `_remove_node` method removes a given node from the list by updating the `prev` and `next` references of its adjacent nodes.

The `_add_to_head` method adds a given node to the front of the list by updating the references of the head node and its adjacent nodes.

This implementation ensures that both the `get` and `put` operations run in O(1) average time complexity since the dictionary provides constant time access to the nodes, and the doubly linked list allows efficient node removal and insertion at the front.